# ğŸ¤– AI ChatRobo â€” Full-Stack AI Chatbot (Python + Groq LLM)

AI ChatRobo is a \*\*full-stack AI chatbot application built entirely in Python\*\*, featuring user authentication, chat history persistence, real-time streaming responses, and a modern Streamlit UI.  

It uses \*\*Groqâ€™s LLM API (LLaMA 3.1)\*\* for ultra-fast inference and a \*\*FastAPI backend\*\* for authentication and data handling.


## ğŸš€ Key Features


### ğŸ” Authentication System

- User registration \& login

- Secure password handling

- Session-based authentication

- Logout \& session reset


### ğŸ’¬ Intelligent Chat Interface

- Real-time AI responses (token streaming)

- Persistent multi-chat history per user

- Automatic chat title generation

- Sidebar chat navigation 


### ğŸ§  AI Engine

- Groq LLM integration (`llama-3.1-8b-instant`)

- System-prompt controlled responses

- Streaming completions for fast UX


### ğŸ—‚ Chat History Management

- Per-user chat storage

- Create, switch, and delete chats

- Clear entire chat history

- Client-side cache + backend sync


## ğŸ—„ Database & Persistence

AI ChatRobo uses SQLite with SQLAlchemy ORM to manage persistent data storage.

Key Highlights:

SQLite database (chatbot.db)

SQLAlchemy ORM for database abstraction

Session-based database access

Safe connection handling using dependency injection

Why SQLite + SQLAlchemy?

Lightweight and easy to configure

Ideal for local development and academic projects

Easily upgradeable to PostgreSQL/MySQL in production

The database layer ensures reliable storage of user data and chat history, making the application scalable and production-ready.


### ğŸ¨ Modern UI (Streamlit)

- Custom login \& signup UI

- Responsive two-column landing page

- Sidebar navigation

- Clean dark-theme styling

- Custom assets \& icons


## ğŸ§± Tech Stack


### Frontend

- \*\*Streamlit\*\*

- Custom CSS

- Session state management


### Backend

- \*\*FastAPI\*\*

- REST APIs for:

&nbsp; - Authentication

&nbsp; - Chat history storage

&nbsp; - Session handling


### AI / LLM

- \*\*Groq API\*\*

- Model: `llama-3.1-8b-instant`

- Streaming responses enabled


### Other

- Python 3.10+

- Requests

- dotenv

- UUID-based chat IDs


## ğŸ“ Project Structure

ai\_chatbot/

â”‚

â”œâ”€â”€ app.py # Streamlit frontend (UI + AI logic)

â”œâ”€â”€ main.py # FastAPI backend entry point

â”œâ”€â”€ auth.py # Authentication logic

â”œâ”€â”€ reset\_password.py # Password reset utilities

â”œâ”€â”€ debug\_auth.py # Auth debugging \& testing

â”œâ”€â”€ verify\_backend.py # Backend verification

â”‚

â”œâ”€â”€ assets/

â”‚ â”œâ”€â”€ robot.png

â”‚ â””â”€â”€ robot\_v2.png

â”‚

â”œâ”€â”€ users.json # User \& chat storage (ignored in git)

â”œâ”€â”€ .env # Environment variables (ignored)

â”œâ”€â”€ .gitignore

â”œâ”€â”€ requirements.txt

â””â”€â”€ README.md


## âš™ï¸ Setup Instructions


### 1ï¸âƒ£ Clone the Repository

git clone https://github.com/AnikaS-23/ai-chatbot-proj.git

cd ai-chatbot-proj

2ï¸âƒ£ Create Virtual Environment

python -m venv venv

venv\\Scripts\\activate   # Windows

3ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

4ï¸âƒ£ Environment Variables

Create a .env file:

GROQ\_API\_KEY=your\_groq\_api\_key\_here

â–¶ï¸ Running the Application

Start Backend (FastAPI)

python main.py

Backend runs at:

http://localhost:8000

Start Frontend (Streamlit)

streamlit run app.py

Frontend runs at:

http://localhost:8501


## ğŸ§ª How It Works (Architecture)

User (Browser)

&nbsp;  â†“

Streamlit Frontend

&nbsp;  â†“ REST API

FastAPI Backend

&nbsp;  â†“

Groq LLM API

- Frontend handles UI \& session state

- Backend manages auth \& chat persistence

- Groq handles AI inference

- Chat responses are streamed token-by-token


## ğŸ”’ Security Notes

API keys stored in .env

Sensitive files ignored via .gitignore

Passwords are never exposed in the frontend


## Author

Anika Sharma

Computer Science Engineering (Data Science)



