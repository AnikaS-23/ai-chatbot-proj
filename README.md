# AI ChatRobo â€” Full-Stack Conversational Intelligence

AI ChatRobo is a high-performance, full-stack AI chatbot application built entirely in Python. The platform features a decoupled architecture, utilizing a **FastAPI** backend for robust data orchestration and a **Streamlit** frontend for a modern, responsive user experience. 

By leveraging **Groqâ€™s LLaMA 3.1** inference engine, AI ChatRobo delivers near-instantaneous, streaming AI responses with persistent chat memory.


## ğŸ›  Technical Architecture

The application follows a client-server model to ensure scalability and separation of concerns:

* **Frontend:** Streamlit-based SPA (Single Page Application) with custom CSS and complex session state management.
* **Backend:** FastAPI REST API managing business logic, authentication, and database transactions.
* **Inference Layer:** Groq Cloud API utilizing the `llama-3.1-8b-instant` model for high-throughput NLP.
* **Data Layer:** SQLite with SQLAlchemy ORM, providing a reliable persistent storage solution for users and chat telemetry.


## ğŸš€ Key Features

### ğŸ” Secure Authentication & Identity
* **User Management:** Full registration and login workflows with secure password handling.
* **Session Security:** Industry-standard hashing and session-based authentication to maintain state across refreshes.
* **Data Isolation:** User data is partitioned at the database level to ensure privacy between accounts.

### ğŸ’¬ Intelligent Chat Interface
* **Real-Time Streaming:** Implements token-by-token streaming for a dynamic UX and reduced perceived latency.
* **Persistent Context:** Multi-chat history allows users to maintain various independent conversation threads.
* **Auto-Titling:** Intelligent generation of chat titles based on the initial user prompt.

### ğŸ—„ Database & Persistence
* **SQLAlchemy ORM:** Provides an abstraction layer for easy migration to enterprise databases like PostgreSQL or MySQL.
* **Thread Safety:** Implements dependency injection for safe, concurrent database connections.


## ğŸ§± Tech Stack

| Component         | Technology                         |
| :---------------- | :--------------------------------- |
| **Language**      | Python 3.10+                       |
| **Backend**       | FastAPI                            |
| **Frontend**      | Streamlit                          |
| **AI Engine**     | Groq (LLaMA 3.1 8B)                |
| **Database**      | SQLite + SQLAlchemy                |
| **Integrations**  | Requests, Dotenv, Pydantic         |

---

## ğŸ“ Project Structure

ai_chatbot/
â”‚
â”œâ”€â”€ app.py                 # Streamlit Frontend (UI & State Logic)
â”œâ”€â”€ main.py                # FastAPI Server (API Entry Point)
â”œâ”€â”€ auth.py                # Identity & Access Management
â”œâ”€â”€ reset_password.py      # Administrative Security Utilities
â”‚
â”œâ”€â”€ database.py            # Database connection (SQLite + SQLAlchemy)
â”œâ”€â”€ models.py              # Database models
â”œâ”€â”€ seed_db.py             # Initial database seeding
â”‚
â”œâ”€â”€ assets/                # Branding & UI Graphics
â”‚
â”œâ”€â”€ requirements.txt       # Project dependencies
â”œâ”€â”€ .env                   # Environment variables (local only)
â”œâ”€â”€ .gitignore             # Version control exclusions
â”œâ”€â”€ chatbot.db             # SQLite database (local)

Note: .env, virtual environment files, and database files are excluded from version control for security and best practices.

## âš™ï¸ Setup Instructions


### 1ï¸âƒ£ Clone the Repository

git clone https://github.com/AnikaS-23/ai-chatbot-proj.git

cd ai-chatbot-proj

2ï¸âƒ£ Create Virtual Environment

python -m venv venv

venv\\Scripts\\activate   # Windows

3ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

4ï¸âƒ£ Environment Variables

Create a .env file:

GROQ\_API\_KEY=your\_groq\_api\_key\_here

â–¶ï¸ Running the Application

Start Backend (FastAPI)

python main.py

Backend runs at:

http://localhost:8000

Start Frontend (Streamlit)

streamlit run app.py

Frontend runs at:

http://localhost:8501

---

### ğŸ§ª How It Works (Architecture)

User (Browser)

&nbsp;  â†“

Streamlit Frontend

&nbsp;  â†“ REST API

FastAPI Backend

&nbsp;  â†“

Groq LLM API

- Frontend handles UI \& session state

- Backend manages auth \& chat persistence

- Groq handles AI inference

- Chat responses are streamed token-by-token

---

### ğŸ”’ Security Notes

API keys stored in .env

Sensitive files ignored via .gitignore

Passwords are never exposed in the frontend


## Author

Anika Sharma

Computer Science Engineering (Data Science)



